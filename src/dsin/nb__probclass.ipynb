{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from enum import Enum, auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbClassifier(nn.Module):\n",
    "    def __init__(self,kernel_size = 3 , ):\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        \n",
    "        K = self.kernel_size\n",
    "        self.filter_shape = (K // 2 + 1, K, K) # CHW\n",
    "        \n",
    "    def create_first_mask(self):\n",
    "            \"\"\"create 5d mask that includes all pixel's in strictly before\"\"\"\n",
    "            K = self.kernel_size\n",
    "            # mask is DHW\n",
    "            mask = torch.ones(self.filter_shape, dtype=torch.float32, requires_grad=False)\n",
    "            # zero out D=1,\n",
    "            # - everything to the right of the central pixel, including the central pixel\n",
    "            mask[-1, K // 2, K // 2:] = 0\n",
    "            # - all rows below the central row\n",
    "            mask[-1, K // 2 + 1:, :] = 0\n",
    "\n",
    "            mask.unsqueeze_(-1).unsqueeze_(-1)  # Make into DHWio, for broadcasting with 3D filters\n",
    "            return nn.Parameter(mask)\n",
    "        \n",
    "    def create_other_mask(self):\n",
    "        \"\"\"create 5d mask that includes all pixel's in before and current pixel\"\"\"\n",
    "        mask = self.create_first_mask()\n",
    "        mask[-1, K // 2, K // 2 + 1] = 1\n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def pad_for_probclass3d(x, context_size, pad_value=0, learn_pad_var=False):\n",
    "    \"\"\"\n",
    "    :param x: NCHW tensor \n",
    "    \"\"\"\n",
    "        pad = context_size // 2\n",
    "        assert pad >= 1\n",
    "        if learn_pad_var:\n",
    "            if not isinstance(pad_value, tf.Variable):\n",
    "                print('Warn: Expected tf.Variable for padding, got {}'.format(pad_value))\n",
    "            return pc_pad_grad(x, pad, pad_value)\n",
    "\n",
    "        pads = [[0, 0],  # don't pad batch dimension\n",
    "                [pad, 0],  # don't pad depth_future, it's not seen by any filter\n",
    "                [pad, pad],\n",
    "                [pad, pad]]\n",
    "        assert len(pads) == _get_ndims(x), '{} != {}'.format(len(pads), x.shape)\n",
    "\n",
    "        pad_fn = tf.pad if input_is_tf else get_np_pad_fn()\n",
    "        return pad_fn(x, pads, constant_values=pad_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def bitcost(self, q, target_symbols, is_training, pad_value=0):\n",
    "        \"\"\"\n",
    "        Pads q, creates PC network, calculates cross entropy between output of PC network and target_symbols\n",
    "        :param q: NCHW\n",
    "        :param target_symbols:\n",
    "        :param is_training:\n",
    "        :return: bitcost per symbol: NCHW\n",
    "        \"\"\"\n",
    "        tf_helpers.assert_ndims(q, 4)\n",
    "\n",
    "        with self._building_ctx(self.reuse):\n",
    "            if self.first_mask is None:\n",
    "                self.first_mask = self.create_first_mask()  # DHWio\n",
    "                self.other_mask = self.create_other_mask()  # DHWio\n",
    "\n",
    "            self.reuse = True\n",
    "\n",
    "            targets_one_hot = tf.one_hot(target_symbols, depth=self.L, axis=-1, name='target_symbols')\n",
    "\n",
    "            q_pad = pad_for_probclass3d(\n",
    "                    q, context_size=self.get_context_size(self.config),\n",
    "                    pad_value=pad_value, learn_pad_var=False)\n",
    "            with tf.variable_scope('logits'):\n",
    "                # make it into NCHWT, where T is the channel dim of the conv3d\n",
    "                q_pad = tf.expand_dims(q_pad, -1, name='NCHWT')\n",
    "                logits = self._logits(q_pad, is_training)\n",
    "\n",
    "            if self.config.regularization_factor is not None:\n",
    "                print('Creating PC regularization...')\n",
    "                weights = _get_all_conv3d_weights_in_scope(self._PROBCLASS_SCOPE)\n",
    "                assert len(weights) > 0\n",
    "                reg = self.config.regularization_factor * tf.add_n(list(map(tf.nn.l2_loss, weights)))\n",
    "                tf.losses.add_loss(reg, tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "\n",
    "            if targets_one_hot.shape.is_fully_defined() and logits.shape.is_fully_defined():\n",
    "                tf_helpers.assert_equal_shape(targets_one_hot, logits)\n",
    "\n",
    "            with tf.name_scope('bitcost'):\n",
    "                # softmax_cross_entropy_with_logits is basis e, change base to 2\n",
    "                log_base_change_factor = tf.constant(np.log2(np.e), dtype=tf.float32)\n",
    "                bc = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=logits, labels=targets_one_hot) * log_base_change_factor  # NCHW\n",
    "\n",
    "            return bc # bit cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('torch': conda)",
   "language": "python",
   "name": "python38264bittorchconda5a49bb01e90b47d3b7ca1c7fc4dc1607"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
