{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Dict, List\n",
    "import enum\n",
    "from enum import Enum\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_p[1]=0.3711006659477778\n",
      "x.shape=torch.Size([1, 2, 3])\n",
      "x=tensor([[[0.1000, 0.9000, 0.3000],\n",
      "         [0.9000, 0.1000, 0.7000]]])\n",
      "loss(x,target_class)=tensor([[0.3711, 0.3711, 0.5130]])\n",
      "loss(x,target_class).shape=torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction='none')#'mean')\n",
    "x =  torch.tensor([[0.1 ,0.9, 0.3],[0.9, 0.1,0.7]]).unsqueeze_(0)\n",
    "x0 = [0.1 , 0.9]\n",
    "softmax_p =-np.log(np.exp(x0)/sum(np.exp(x0)))\n",
    "\n",
    "target_class = torch.tensor([1, 0 ,1]).unsqueeze_(0)\n",
    "print(f\"{softmax_p[1]=}\")\n",
    "print(f\"{x.shape=}\")\n",
    "print(f\"{x=}\")\n",
    "print(f\"{loss(x,target_class)=}\")\n",
    "print(f\"{loss(x,target_class).shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3679318490315369"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(0.3133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8333333333333334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0.9 -0.9  -0.7) /3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4493279989401402"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(0.3711)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21194156 0.21194156 0.57611688]\n",
      "0.21194155761708547\n",
      "0.5761168847658291\n"
     ]
    }
   ],
   "source": [
    "x = [0.0 ,0.0 , 1.0]\n",
    "print(np.exp(x)/sum(np.exp(x)))\n",
    "print(1.0/(2 + np.exp(1)))\n",
    "print(np.exp(1)/(2 + np.exp(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([1, 2, 3])\n",
      "x=tensor([[[0.1000, 0.9000, 0.3000],\n",
      "         [0.9000, 0.1000, 0.7000]]])\n",
      "y=tensor([[0.1000, 0.9000, 0.3000],\n",
      "        [0.9000, 0.1000, 0.7000]])\n",
      "y.shape=torch.Size([2, 3])\n",
      "z=tensor(0.5000)\n",
      "z.shape=torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "x =  torch.tensor([[0.1 ,0.9, 0.3],[0.9, 0.1,0.7]]).unsqueeze_(0)\n",
    "print(f\"{x.shape=}\")\n",
    "print(f\"{x=}\")\n",
    "y= torch.mean(x, dim=0)\n",
    "print(f\"{y=}\")\n",
    "print(f\"{y.shape=}\")\n",
    "\n",
    "z= torch.mean(x)\n",
    "print(f\"{z=}\")\n",
    "print(f\"{z.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1000, 0.9000, 0.3000],\n",
       "         [0.9000, 0.1000, 0.7000]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.1000, 1.9000, 1.3000],\n",
       "         [1.9000, 1.1000, 1.7000]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    " x = nn.Conv2d(\n",
    "                    in_channels=32,\n",
    "                    out_channels=32,\n",
    "                    kernel_size=[3, 3],\n",
    "                  \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    w = torch.eye(\n",
    "        n=x.kernel_size[0], dtype=torch.float32\n",
    "    ).repeat(x.weight.shape[0], x.weight.shape[1], 1, 1)\n",
    "\n",
    "    x.weight = nn.Parameter(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 1.]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0014,  0.0241,  0.0056, -0.0059, -0.0080,  0.0319,  0.0060, -0.0462,\n",
      "         0.0169,  0.0489,  0.0572,  0.0151, -0.0139,  0.0042,  0.0326,  0.0480,\n",
      "         0.0388,  0.0571, -0.0498, -0.0473, -0.0577,  0.0331,  0.0462, -0.0026,\n",
      "        -0.0209,  0.0353, -0.0228,  0.0244,  0.0154,  0.0351,  0.0297, -0.0318],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in x.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.0576,  0.1122,  0.0262],\n",
       "          [ 0.0661, -0.1964, -0.1904],\n",
       "          [-0.0321,  0.0543, -0.1121]],\n",
       "\n",
       "         [[ 0.0674,  0.0942, -0.0026],\n",
       "          [-0.1720,  0.0449, -0.2070],\n",
       "          [ 0.1315, -0.1814, -0.0462]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1637,  0.1197, -0.0227],\n",
       "          [-0.0492, -0.2256, -0.0596],\n",
       "          [-0.1591,  0.1324,  0.2147]],\n",
       "\n",
       "         [[ 0.1496,  0.0868,  0.2316],\n",
       "          [ 0.2255,  0.0375, -0.2177],\n",
       "          [ 0.1986,  0.1989,  0.0149]]]], requires_grad=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3]])\n",
      "torch.Size([3])\n",
      "torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "print(x.repeat(4, 2))\n",
    "print(x.shape)\n",
    "print(x.repeat(4, 2, 1).size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0\n",
      "t=54\n",
      "i=1\n",
      "t=6\n",
      "i=2\n",
      "t=7\n",
      "i=3\n",
      "t=4\n"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate([54,6,7,4]):\n",
    "    print(f\"{i=}\")\n",
    "    print(f\"{t=}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('torch': conda)",
   "language": "python",
   "name": "python38264bittorchconda5a49bb01e90b47d3b7ca1c7fc4dc1607"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
