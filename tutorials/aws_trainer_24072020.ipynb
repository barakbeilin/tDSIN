{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import torch\n",
    "from torch import nn\n",
    "from dsin.ae.data_manager.data_loader import (\n",
    "    SideinformationImageImageList, ImageSiTuple)\n",
    "from dsin.ae import config\n",
    "from dsin.ae.si_ae import SideInformationAutoEncoder\n",
    "from dsin.ae.si_net import SiNetChannelIn\n",
    "from dsin.ae.loss_man import LossManager\n",
    "from dsin.ae.distortions import Distortions, DistTypes\n",
    "from dsin.ae.kitti_normalizer import ChangeImageStatsToKitti, ChangeState\n",
    "from dsin.ae import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.H_target = 2* 0.3\n",
    "config.autoencoder_loss_distortion_to_minimize=DistTypes.MS_SSMIM\n",
    "config.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMetric(Callback):\n",
    "    \"Wrap a `func` in a callback for metrics computation.\"\n",
    "    def __init__(self, func,name):\n",
    "        # If it's a partial, use func.func\n",
    "        #         name = getattr(func,'func',func).__name__\n",
    "        self.func, self.name = func, name\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        \"Set the inner value to 0.\"\n",
    "        self.val, self.count = 0.,0\n",
    "\n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        \"Update metric computation with `last_output` and `last_target`.\"\n",
    "        if not is_listy(last_target): last_target=[last_target]\n",
    "        self.count += last_target[0].size(0) # batch size\n",
    "        X_DEC_IND =1\n",
    "        val = self.func(last_output[X_DEC_IND], last_target[0])\n",
    "        self.val += last_target[0].size(0) * val.detach().cpu()\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        \"Set the final result in `last_metrics`.\"\n",
    "        return add_metrics(last_metrics, self.val/self.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SiNetChannelIn.WithSideInformation: 6>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.use_si_flag = SiNetChannelIn.WithSideInformation\n",
    "config.use_si_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_autoencoder = SideInformationAutoEncoder(config.use_si_flag)\n",
    "path = \"../src/dsin/data\"\n",
    "pct= 0.25 #0.0005 #0.25\n",
    "valid_image_list = SideinformationImageImageList.from_csv(\n",
    "    path=path, csv_names=[\"KITTI_general_val.txt\"],pct=pct)\n",
    "train_image_list = SideinformationImageImageList.from_csv(\n",
    "    path=path, csv_names=[\"KITTI_general_train.txt\"],pct=pct)\n",
    "\n",
    "image_lists = ItemLists(\n",
    "    path=path, train=train_image_list, valid=valid_image_list)\n",
    "\n",
    "# ll = image_lists.label_from_func(lambda x: x)\n",
    "\n",
    "tfms = None #get_transforms(do_flip=True, max_rotate=0.0)\n",
    "batchsize = 1\n",
    "data = (image_lists\n",
    "        .label_from_func(lambda x: x)\n",
    "        .transform(tfms, size=(336, 1224), resize_method=ResizeMethod.CROP, tfm_y=True)\n",
    "        .databunch(bs=batchsize))\n",
    "learn = Learner(data=data,\n",
    "                     model=si_autoencoder,\n",
    "                     opt_func=torch.optim.Adam,\n",
    "                     loss_func=LossManager(config.use_si_flag),\n",
    "                     metrics=[AverageMetric(Distortions._calc_dist,\"MS_SSIM\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>MS_SSIM</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>413.701965</td>\n",
       "      <td>495.271118</td>\n",
       "      <td>4040.383789</td>\n",
       "      <td>2:01:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.model.true_tuple_loss_false_just_out = True\n",
    "learn.model.use_side_infomation = SiNetChannelIn.NoSideInformation\n",
    "learn.loss_func.use_side_infomation = SiNetChannelIn.NoSideInformation\n",
    "learn.fit(1, lr=0.0005)\n",
    "learn.save('0.5-ae-for-si')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = load_learner('ae-for-si')\n",
    "learn.loss_func.bit_cost_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.model.true_tuple_loss_false_just_out = True\n",
    "# learn.model.use_side_infomation = SiNetChannelIn.NoSideInformation\n",
    "# learn.loss_func.use_side_infomation = SiNetChannelIn.NoSideInformation\n",
    "# out =learn.model(learn.data.train_ds[0][0].img.data.unsqueeze(0).cuda()\n",
    "#                   ,learn.data.train_ds[0][0].si_img.data.unsqueeze(0).cuda())\n",
    "# out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('mssim -lr0p0005 -full-stage-1')\n",
    "\n",
    "# learn.model.true_tuple_loss_false_just_out = False\n",
    "\n",
    "# learn.show_results(figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>MS_SSIM</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='20614' class='' max='43734', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      47.13% [20614/43734 3:56:52<4:25:40 331.5881]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.load('0.5-ae-for-si')\n",
    "learn.model.true_tuple_loss_false_just_out = True\n",
    "learn.model.use_side_infomation = SiNetChannelIn.WithSideInformation #SiNetChannelIn.NoSideInformation\n",
    "learn.loss_func.use_side_infomation = SiNetChannelIn.WithSideInformation # SiNetChannelIn.NoSideInformation\n",
    "learn.fit(1, lr=0.0005)\n",
    "learn.save('si-0.5-ae-for-si')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(learn.model.my_tuple[0].squeeze_()/255)\n",
    "learn.model.my_tuple[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(learn.model.my_tuple[0].squeeze_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.true_tuple_loss_false_just_out = False\n",
    "\n",
    "learn.show_results(figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.model.true_tuple_loss_false_just_out = True\n",
    "\n",
    "# learn.fit(1, lr=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.x_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('mssim -lr0p0005 -full-stage-1')\n",
    "# learn.model.true_tuple_loss_false_just_out = True\n",
    "\n",
    "# learn.fit(1, lr=0.0005,wd=0.0001)\n",
    "# learn.save('mssim -lr0p00005 -full-stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit(1, lr=0.0005,wd=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('mssim -lr0p0005 -full-stage-1')\n",
    "\n",
    "# learn.model.true_tuple_loss_false_just_out = False\n",
    "\n",
    "# learn.show_results(figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# learn.model.true_tuple_loss_false_just_out = True\n",
    "\n",
    "# for i in range(4):\n",
    "#     lr = 0.0001\n",
    "#     wd = 0.0001\n",
    "#     learn.fit(1, lr=lr,wd=wd)\n",
    "# #     learn.save(f'mssim -full-stage-{i} -lr{lr} -wd{wd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # my_learner.fit_one_cycle(10)\n",
    "# # my_learner.lr_find()\n",
    "# # my_learner.save('stage-1')\n",
    "# # my_learner.recorder.plot()\n",
    "# # my_learner.load('stage-1')\n",
    "# # my_learner.save(\"trained_model-stage1\", return_path=True)\n",
    "# # my_learner.export(\"trained_model_ex_stage1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
