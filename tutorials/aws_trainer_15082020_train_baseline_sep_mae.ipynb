{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from dsin.ae.data_manager.data_loader import (\n",
    "    SideinformationImageImageList, ImageSiTuple)\n",
    "from dsin.ae import config\n",
    "from dsin.ae.base_ae import BaseAutoEncoder\n",
    "from dsin.ae.si_net import SiNetChannelIn\n",
    "from dsin.ae.loss_man import LossManager\n",
    "from dsin.ae.distortions import Distortions, DistTypes\n",
    "from dsin.ae.kitti_normalizer import ChangeImageStatsToKitti, ChangeState\n",
    "from dsin.ae import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.H_target = 2* 0.3\n",
    "# config.autoencoder_loss_distortion_to_minimize=DistTypes.MS_SSMIM\n",
    "config.K_MS_SSIM=500\n",
    "config.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def setup_file_logger(log_file='out.log'):\n",
    "    hdlr = logging.FileHandler(log_file)\n",
    "    formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "    hdlr.setFormatter(formatter)\n",
    "    logger.addHandler(hdlr) \n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.info(\"start\")\n",
    "\n",
    "setup_file_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMetric(Callback):\n",
    "    \"Wrap a `func` in a callback for metrics computation.\"\n",
    "    def __init__(self, func,name):\n",
    "        # If it's a partial, use func.func\n",
    "        #         name = getattr(func,'func',func).__name__\n",
    "        self.func, self.name = func, name\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        \"Set the inner value to 0.\"\n",
    "        self.val, self.count = 0.,0\n",
    "\n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        \"Update metric computation with `last_output` and `last_target`.\"\n",
    "        if not is_listy(last_target): last_target=[last_target]\n",
    "        self.count += last_target[0].size(0) # batch size\n",
    "        \n",
    "        if last_output[0] is None:\n",
    "            X_OUTPUT = 1 # X_DEC\n",
    "        else:\n",
    "            X_OUTPUT = 0 # X_HAT_OUT\n",
    "        val = self.func(last_output[X_OUTPUT], last_target[0])\n",
    "        self.val += last_target[0].size(0) * val.detach().cpu()\n",
    "        \n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        \"Set the final result in `last_metrics`.\"\n",
    "        return add_metrics(last_metrics, self.val/self.count)\n",
    "    \n",
    "class ParameterMetricCallback(Callback):\n",
    "    def __init__(self,loss_man):\n",
    "        self.loss_man = loss_man\n",
    "    \n",
    "    def on_backward_begin(self,*args, **kwargs):\n",
    "        self.pbar=kwargs[\"pbar\"]\n",
    "        if hasattr(self.loss_man,'soft_bit_entropy'):\n",
    "            self.pbar.child.comment += f' soft_bit_entropy: {self.loss_man.soft_bit_entropy:.4f}'\n",
    "\n",
    "class ParameterRunningAverageMetricCallback(Callback):\n",
    "    def __init__(self,loss_man,alpha=0.1):\n",
    "        self.loss_man = loss_man\n",
    "        self.alpha = alpha\n",
    "        self.val = None\n",
    "    \n",
    "    def on_backward_begin(self,*args, **kwargs):\n",
    "        self.pbar=kwargs[\"pbar\"]\n",
    "        self.importance_map=kwargs[\"last_output\"][3].detach()\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "        if hasattr(self.loss_man,'soft_bit_entropy'):\n",
    "            if self.val is None:\n",
    "                self.val = self.loss_man.soft_bit_entropy.detach()\n",
    "            else:\n",
    "                self.val *= 1 - self.alpha\n",
    "                self.val += self.alpha * self.loss_man.soft_bit_entropy.detach()\n",
    "\n",
    "        self.pbar.child.comment += f' avg_bpp: {self.val / 2 :.4f} imp-mean-var {(torch.mean(self.importance_map),torch.var(self.importance_map))}'\n",
    "        msg = f\"bitcost_loss={self.loss_man.bit_cost_loss_value:.1f} \"\n",
    "        msg += f\"l2reg_loss={self.loss_man.l2_reg_loss:.1f} \"\n",
    "        msg += f\"autoencoder_loss_value={ self.loss_man.autoencoder_loss_value:.1f} \"\n",
    "        msg += f\"si_loss={self.loss_man.si_net_loss_value} \"\n",
    "        self.pbar.child.comment += msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitEntropy(Callback):\n",
    "    \"Wrap a `func` in a callback for metrics computation.\"\n",
    "    def __init__(self,loss_man,alpha=0.1, logger=logger):\n",
    "        # If it's a partial, use func.func\n",
    "        #         name = getattr(func,'func',func).__name__\n",
    "        self.loss_man = loss_man\n",
    "        self.alpha = alpha\n",
    "        self.logger = logger\n",
    "        \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        \"Set the inner value to 0.\"\n",
    "        self.val = 0.0\n",
    "        self.iter = 0\n",
    "        \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        \"Update metric computation with `last_output` and `last_target`.\"\n",
    "      \n",
    "        self.val *= 1 - self.alpha\n",
    "        self.val += self.alpha * self.loss_man.soft_bit_entropy.detach()\n",
    "\n",
    "        if self.iter % 500 == 0 :\n",
    "            importance_map  = last_output[3].detach()\n",
    "            msg = f\"iter {self.iter}: bpp = {self.val / 2:.3f}, impmap- mean {torch.mean(importance_map):.4f} var {torch.var(importance_map):.4f} \"\n",
    "            msg += f\" total loss{self.loss_man.total_loss:.1f}  l2reg_loss={self.loss_man.l2_reg_loss:.1f}\"\n",
    "            msg += f\"autoencoder_loss_value={ self.loss_man.autoencoder_loss_value:.1f}\"\n",
    "            msg += f\"si_loss={self.loss_man.si_net_loss_value}\"\n",
    "            self.logger.info(msg)\n",
    "            print(msg)\n",
    "        self.iter += 1\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        \"Set the final result in `last_metrics`.\"\n",
    "        return add_metrics(last_metrics, self.val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SiNetChannelIn.WithSideInformation: 6>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.use_si_flag = SiNetChannelIn.WithSideInformation\n",
    "config.use_si_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = nn.Sequential(nn.Conv2d(in_channels=2,out_channels=3 , kernel_size=1),nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_autoencoder = BaseAutoEncoder()\n",
    "path = \"../src/dsin/data\"\n",
    "pct= 1 #0.0005 #0.25\n",
    "\n",
    "valid_image_list = SideinformationImageImageList.from_csv(\n",
    "    path=path, csv_names=[\"KITTI_baseline_val.txt\"],pct=pct)\n",
    "train_image_list = SideinformationImageImageList.from_csv(\n",
    "    path=path, csv_names=[\"KITTI_baseline_train.txt\"],pct=pct)\n",
    "\n",
    "image_lists = ItemLists(\n",
    "    path=path, train=train_image_list, valid=valid_image_list)\n",
    "\n",
    "\n",
    "tfms =  get_transforms(do_flip=True, flip_vert=False, max_rotate=None, max_zoom=1., max_lighting=None, max_warp=None, p_affine=0.0, p_lighting=0.0)\n",
    "\n",
    "batchsize = 1\n",
    "\n",
    "data = (image_lists\n",
    "        .label_from_func(lambda x: x)\n",
    "        .transform(None, size=(336, 1224), resize_method=ResizeMethod.CROP, tfm_y=True)\n",
    "        .databunch(bs=batchsize))\n",
    "\n",
    "learn = Learner(data=data,\n",
    "                     model=baseline_autoencoder,\n",
    "                     opt_func=torch.optim.Adam,\n",
    "                     loss_func=LossManager(SiNetChannelIn.NoSideInformation),\n",
    "                     metrics=[AverageMetric(Distortions._calc_dist,\"MS_SSIM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>MS_SSIM</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4424' class='' max='32232', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      13.73% [4424/32232 13:02<1:21:56 695.7695 avg_bpp: 0.6291 imp-mean-var (tensor(0.3786, device='cuda:0'), tensor(0.2352, device='cuda:0'))bitcost_loss=670.7 l2reg_loss=27.9 autoencoder_loss_value=21.6 si_loss=0 ]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: bpp = 0.096, impmap- mean 0.5093 var 0.2486  total loss1443.9  l2reg_loss=37.1autoencoder_loss_value=92.6si_loss=0\n",
      "iter 500: bpp = 0.584, impmap- mean 0.0543 var 0.0514  total loss625.8  l2reg_loss=34.0autoencoder_loss_value=44.5si_loss=0\n",
      "iter 1000: bpp = 0.490, impmap- mean 0.0456 var 0.0435  total loss422.1  l2reg_loss=32.2autoencoder_loss_value=38.3si_loss=0\n",
      "iter 1500: bpp = 0.392, impmap- mean 0.0376 var 0.0362  total loss257.4  l2reg_loss=31.2autoencoder_loss_value=36.3si_loss=0\n",
      "iter 2000: bpp = 0.333, impmap- mean 0.0370 var 0.0356  total loss129.6  l2reg_loss=30.4autoencoder_loss_value=33.8si_loss=0\n",
      "iter 2500: bpp = 0.336, impmap- mean 0.0387 var 0.0371  total loss56.3  l2reg_loss=29.8autoencoder_loss_value=26.5si_loss=0\n",
      "iter 3000: bpp = 0.332, impmap- mean 0.0972 var 0.0877  total loss133.3  l2reg_loss=29.3autoencoder_loss_value=21.2si_loss=0\n",
      "iter 3500: bpp = 0.475, impmap- mean 0.1939 var 0.1563  total loss366.7  l2reg_loss=28.9autoencoder_loss_value=31.3si_loss=0\n",
      "iter 4000: bpp = 0.689, impmap- mean 0.3825 var 0.2362  total loss780.5  l2reg_loss=28.4autoencoder_loss_value=24.6si_loss=0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_fname = '200816MAE-l2reg-baseline'\n",
    "for i in range(1,5):\n",
    "    if i != 1 :\n",
    "        learn.load(f'{model_fname}-{i - 1}',with_opt=True)\n",
    "    \n",
    "    config.si_loss_weight_alpha = 0\n",
    "    learn.model.true_tuple_loss_false_just_out = True\n",
    "    learn.model.use_side_infomation = SiNetChannelIn.NoSideInformation\n",
    "    learn.loss_func.use_side_infomation = SiNetChannelIn.NoSideInformation\n",
    "    learn.fit(1, lr=0.0001,wd=0,callbacks=[ParameterRunningAverageMetricCallback(learn.loss_func),BitEntropy(loss_man=learn.loss_func)])\n",
    "    learn.save(f'{model_fname}-{i}')\n",
    "    !aws s3 cp ~/tDSIN/src/dsin/data/models/{model_fname}-{i}.pth  s3://dsin-us/models/\n",
    "    !aws s3 cp ~/tDSIN/tutorials/out.log s3://dsin-us/models/{model_fname}.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'{model_fname}-{i}')\n",
    "\n",
    "!aws s3 cp ~/tDSIN/src/dsin/data/models/{model_fname}-{i}.pth  s3://dsin-us/models/\n",
    "!aws s3 cp ~/tDSIN/tutorials/out.log s3://dsin-us/models/{model_fname}.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.my_tuple[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.train_ds[1][0].img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.train_ds[1][0].si_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func.soft_bit_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.si_loss_weight_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func.autoencoder_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('try2_200807MAE-l2reg-baseline-2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = learn.model.my_tuple[-1].squeeze_().detach()\n",
    "mx, mn =torch.max(mt), torch.min(mt)\n",
    "diff = mx-mn\n",
    "show_image(Image((mt - mn)/(diff)),figsize=(30,30))\n",
    "# # print(mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # show_image(Image(learn.model.my_tuple[0][:,:50,:50]/255))\n",
    "# # Image(learn.model.my_tuple[2].squeeze_().detach()/255.0)\n",
    "mt = learn.model.my_tuple[0].squeeze_().detach()\n",
    "mx, mn =torch.max(mt), torch.min(mt)\n",
    "diff = mx-mn\n",
    "show_image(Image((mt - mn)/(diff)),figsize=(30,30))\n",
    "# # print(mn)\n",
    "\n",
    "# torch.min(learn.model.my_tuple[2].squeeze_().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = (mt - mn)/(diff)\n",
    "\n",
    "flip_lr(Image(aaa.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.model.true_tuple_loss_false_just_out = False\n",
    "\n",
    "# learn.show_results(figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.my_tuple[-2].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
